<?xml version="1.0" encoding="UTF-8"?>
<project xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xmlns="http://maven.apache.org/POM/4.0.0"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">

	<modelVersion>4.0.0</modelVersion>
	<groupId>com.greatergood.analytics</groupId>
	<artifactId>analytics-logs</artifactId>
	<version>1.0-SNAPSHOT</version>
	<properties>
		<hbase.version>1.1.1</hbase.version>
		<scala.binary.version>2.10</scala.binary.version>
		<scala.version>2.10.5</scala.version>
		<scala.macros.version>2.0.1</scala.macros.version>
		<spark.version>1.6.0</spark.version>
		<scala.java.version>1.8</scala.java.version>
		<jar.base.name>log-reader</jar.base.name>
		<PermGen>64m</PermGen>
		<MaxPermGen>512m</MaxPermGen>
	</properties>

	<dependencies>
		<!--Spark-->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.json4s</groupId>
					<artifactId>json4s-jackson_${scala.binary.version}</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.typesafe</groupId>
					<artifactId>config</artifactId>
				</exclusion>
			</exclusions>
			<scope>provided</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-graphx_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.json4s</groupId>
					<artifactId>json4s-jackson_${scala.binary.version}</artifactId>
				</exclusion>
			</exclusions>
			<scope>provided</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.json4s</groupId>
					<artifactId>json4s-jackson_${scala.binary.version}</artifactId>
				</exclusion>
			</exclusions>
			<scope>provided</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.json4s</groupId>
					<artifactId>json4s-jackson_${scala.binary.version}</artifactId>
				</exclusion>
			</exclusions>
			<scope>provided</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.json4s</groupId>
					<artifactId>json4s-jackson_${scala.binary.version}</artifactId>
				</exclusion>
			</exclusions>
			<scope>provided</scope>
		</dependency>

		<dependency>
			<groupId>org.postgresql</groupId>
			<artifactId>postgresql</artifactId>
			<version>42.0.0.jre7</version>
		</dependency>

		<dependency>
			<groupId>org.scalikejdbc</groupId>
			<artifactId>scalikejdbc_${scala.binary.version}</artifactId>
			<version>2.5.1</version>
		</dependency>

		<dependency>
			<groupId>org.json4s</groupId>
			<artifactId>json4s-jackson_${scala.binary.version}</artifactId>
			<version>3.2.10</version>
			<!--<version>3.5.0</version>-->
		</dependency>

		<dependency>
			<groupId>com.google.guava</groupId>
			<artifactId>guava</artifactId>
			<version><!--18.0-->12.0.1</version>
		</dependency>

		<dependency>
			<groupId>redis.clients</groupId>
			<artifactId>jedis</artifactId>
			<version>2.6.2</version>
		</dependency>

		<dependency>
			<groupId>com.github.scopt</groupId>
			<artifactId>scopt_${scala.binary.version}</artifactId>
			<version>3.2.0</version>
		</dependency>

		<dependency>
			<groupId>RedisLabs</groupId>
			<artifactId>spark-redis</artifactId>
			<version>0.3.2</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-yarn_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.json4s</groupId>
					<artifactId>json4s-jackson_${scala.binary.version}</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>com.holdenkarau</groupId>
			<artifactId>spark-testing-base_${scala.binary.version}</artifactId>
			<version>2.0.0_0.6.0</version>
		</dependency>
		<dependency>
			<groupId>com.h2database</groupId>
			<artifactId>h2</artifactId>
			<version>1.4.194</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>com.typesafe.play</groupId>
			<artifactId>play-jdbc-evolutions_${scala.binary.version}</artifactId>
			<version>2.4.11</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>com.typesafe</groupId>
			<artifactId>config</artifactId>
			<version>1.3.0</version>
			<!--<scope>test</scope>-->
		</dependency>
		<dependency>
			<groupId>com.typesafe.play</groupId>
			<artifactId>play-jdbc_${scala.binary.version}</artifactId>
			<version>2.4.11</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>commons-codec</groupId>
			<artifactId>commons-codec</artifactId>
			<version>1.10</version>
			<scope>test</scope>
		</dependency>
	</dependencies>
	<repositories>
		<repository>
			<id>spark.redis</id>
			<name>Spark Redis</name>
			<url>https://dl.bintray.com/spark-packages/maven/</url>
		</repository>
	</repositories>
	<build>
		<outputDirectory>target/scala-${scala.binary.version}/classes</outputDirectory>
		<testOutputDirectory>target/scala-${scala.binary.version}/test-classes</testOutputDirectory>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-deploy-plugin</artifactId>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-install-plugin</artifactId>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>build-helper-maven-plugin</artifactId>
				<executions>
					<execution>
						<id>add-scala-sources</id>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/main/scala</source>
								<!--<source>scala-${scala.binary.version}/src/main/scala</source>
								<source>scala-${scala.binary.version}/src/main/java</source>-->
							</sources>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<configuration>
					<shadedArtifactAttached>false</shadedArtifactAttached>
					<outputFile>
						${project.build.directory}/scala-${scala.binary.version}/${jar.base.name}-${project.version}.jar
					</outputFile>
					<artifactSet>
						<includes>
							<include>*:*</include>
						</includes>
					</artifactSet>
					<filters>
						<filter>
							<artifact>com.google.guava:guava</artifact>
							<excludes>
								<exclude>com/google/common/base/Optional*</exclude>
							</excludes>
						</filter>
						<filter>
							<artifact>*:*</artifact>
							<excludes>
								<exclude>META-INF/*.SF</exclude>
								<exclude>META-INF/*.DSA</exclude>
								<exclude>META-INF/*.RSA</exclude>
							</excludes>
						</filter>
					</filters>
				</configuration>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
						<configuration>
							<relocations>
								<relocation>
									<pattern>com.google</pattern>
									<shadedPattern>org.spark-project.guava</shadedPattern>
									<includes>
										<include>com.google.common.**</include>
									</includes>
									<excludes>
										<exclude>com.google.common.base.Optional**</exclude>
									</excludes>
								</relocation>
								<relocation>
									<pattern>org.apache.commons.math3</pattern>
									<shadedPattern>org.spark-project.commons.math3</shadedPattern>
								</relocation>
							</relocations>
							<transformers>
								<transformer
										implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
								<transformer
										implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
									<resource>reference.conf</resource>
								</transformer>
								<transformer
										implementation="org.apache.maven.plugins.shade.resource.DontIncludeResourceTransformer">
									<resource>log4j.properties</resource>
								</transformer>
							</transformers>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<plugin>
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<version>3.2.0</version>
				<executions>
					<execution>
						<id>scala-compile-first</id>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
					<execution>
						<id>scala-test-compile-first</id>
						<phase>process-test-resources</phase>
						<goals>
							<goal>testCompile</goal>
						</goals>
					</execution>
					<execution>
						<id>attach-scaladocs</id>
						<phase>verify</phase>
						<goals>
							<goal>doc-jar</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<scalaVersion>${scala.version}</scalaVersion>
					<recompileMode>incremental</recompileMode>
					<useZincServer>true</useZincServer>
					<args>
						<arg>-unchecked</arg>
						<arg>-deprecation</arg>
						<arg>-feature</arg>
					</args>
					<jvmArgs>
						<jvmArg>-Xms1024m</jvmArg>
						<jvmArg>-Xmx1024m</jvmArg>
						<jvmArg>-XX:PermSize=${PermGen}</jvmArg>
						<jvmArg>-XX:MaxPermSize=${MaxPermGen}</jvmArg>
					</jvmArgs>
					<javacArgs>
						<javacArg>-source</javacArg>
						<javacArg>${scala.java.version}</javacArg>
						<javacArg>-target</javacArg>
						<javacArg>${scala.java.version}</javacArg>
					</javacArgs>
					<!-- The following plugin is required to use quasiquotes in Scala 2.10 and is used
						 by Spark SQL for code generation. -->
					<!--<compilerPlugins>
						<compilerPlugin>
							<groupId>org.scalamacros</groupId>
							<artifactId>paradise_${scala.version}</artifactId>
							<version>${scala.macros.version}</version>
						</compilerPlugin>
					</compilerPlugins>-->
				</configuration>
			</plugin>

			<!--<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<version>2.17</version>
				<configuration>
					 Uses scalatest instead
					<skipTests>true</skipTests>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.scalatest</groupId>
				<artifactId>scalatest-maven-plugin</artifactId>
				<version>1.0</version>
				<configuration>
					<reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
					<junitxml>.</junitxml>
					<filereports>SparkTestSuite.txt</filereports>
					<argLine>-Xmx3g -XX:MaxPermSize=${MaxPermGen} -XX:ReservedCodeCacheSize=512m</argLine>
					<stderr/>
					<systemProperties>
						<java.awt.headless>true</java.awt.headless>
						<spark.test.home>${session.executionRootDirectory}</spark.test.home>
						<spark.testing>1</spark.testing>
						<spark.ui.enabled>false</spark.ui.enabled>
						<spark.ui.showConsoleProgress>false</spark.ui.showConsoleProgress>
						<spark.executor.extraClassPath>${test_classpath}</spark.executor.extraClassPath>
						<spark.driver.allowMultipleContexts>true</spark.driver.allowMultipleContexts>
					</systemProperties>
				</configuration>
				<executions>
					<execution>
						<id>test</id>
						<goals>
							<goal>test</goal>
						</goals>
					</execution>
				</executions>
			</plugin>-->

		</plugins>

	</build>

</project>